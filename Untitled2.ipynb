{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "591e0943-59d3-4dd0-a90e-59622f26fa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (80000, 28)\n",
      "Test data shape: (20000, 27)\n",
      "Missing values in training data:\n",
      "ID                              0\n",
      "Customer_ID                     0\n",
      "Month                           0\n",
      "Name                         8029\n",
      "Age                             0\n",
      "Number                          0\n",
      "Profession                      0\n",
      "Income_Annual                   0\n",
      "Base_Salary_PerMonth        12032\n",
      "Total_Bank_Accounts             0\n",
      "Total_Credit_Cards              0\n",
      "Rate_Of_Interest                0\n",
      "Total_Current_Loans             0\n",
      "Loan_Type                    9157\n",
      "Delay_from_due_date             0\n",
      "Total_Delayed_Payments       5595\n",
      "Credit_Limit                    0\n",
      "Total_Credit_Enquiries       1549\n",
      "Credit_Mix                      0\n",
      "Current_Debt_Outstanding        0\n",
      "Ratio_Credit_Utilization        0\n",
      "Credit_History_Age           7240\n",
      "Payment_of_Min_Amount           0\n",
      "Per_Month_EMI                   0\n",
      "Monthly_Investment           3605\n",
      "Payment_Behaviour               0\n",
      "Monthly_Balance               950\n",
      "Credit_Score                    0\n",
      "dtype: int64\n",
      "Data types in training data:\n",
      "ID                           object\n",
      "Customer_ID                  object\n",
      "Month                        object\n",
      "Name                         object\n",
      "Age                          object\n",
      "Number                       object\n",
      "Profession                   object\n",
      "Income_Annual                object\n",
      "Base_Salary_PerMonth        float64\n",
      "Total_Bank_Accounts           int64\n",
      "Total_Credit_Cards            int64\n",
      "Rate_Of_Interest              int64\n",
      "Total_Current_Loans          object\n",
      "Loan_Type                    object\n",
      "Delay_from_due_date           int64\n",
      "Total_Delayed_Payments       object\n",
      "Credit_Limit                 object\n",
      "Total_Credit_Enquiries      float64\n",
      "Credit_Mix                   object\n",
      "Current_Debt_Outstanding     object\n",
      "Ratio_Credit_Utilization    float64\n",
      "Credit_History_Age           object\n",
      "Payment_of_Min_Amount        object\n",
      "Per_Month_EMI               float64\n",
      "Monthly_Investment           object\n",
      "Payment_Behaviour            object\n",
      "Monthly_Balance              object\n",
      "Credit_Score                 object\n",
      "dtype: object\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "\n",
      "Best performing model: XGBoost with accuracy: 0.7775\n",
      "\n",
      "Predictions have been saved to 'credit_score_predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the dataset\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values in training data:\")\n",
    "print(train_data.isnull().sum())\n",
    "\n",
    "# Display data types of columns\n",
    "print(\"Data types in training data:\")\n",
    "print(train_data.dtypes)\n",
    "\n",
    "# Clean numeric columns\n",
    "columns_to_clean = ['Age', 'Income_Annual', 'Current_Debt_Outstanding', 'Monthly_Investment', \n",
    "                    'Monthly_Balance', 'Total_Current_Loans', 'Total_Delayed_Payments', 'Credit_Limit']\n",
    "for col in columns_to_clean:\n",
    "    train_data[col] = pd.to_numeric(train_data[col].replace('[^0-9.]', '', regex=True), errors='coerce')\n",
    "    test_data[col] = pd.to_numeric(test_data[col].replace('[^0-9.]', '', regex=True), errors='coerce')\n",
    "\n",
    "# Drop irrelevant columns\n",
    "train_data.drop(columns=['Customer_ID', 'Name', 'Number'], inplace=True)\n",
    "test_data.drop(columns=['Customer_ID', 'Name', 'Number'], inplace=True)\n",
    "\n",
    "# Replace placeholders with NaN\n",
    "train_data['Profession'] = train_data['Profession'].replace('_', np.nan)\n",
    "test_data['Profession'] = test_data['Profession'].replace('_', np.nan)\n",
    "train_data['Credit_Mix'] = train_data['Credit_Mix'].replace('_', np.nan)\n",
    "test_data['Credit_Mix'] = test_data['Credit_Mix'].replace('_', np.nan)\n",
    "\n",
    "# Convert credit history age to months\n",
    "def Month_Converter(val):\n",
    "    if pd.notnull(val):\n",
    "        years = int(val.split(' ')[0])\n",
    "        month = int(val.split(' ')[3])\n",
    "        return (years * 12) + month\n",
    "    else:\n",
    "        return val\n",
    "\n",
    "train_data['Credit_History_Age'] = train_data['Credit_History_Age'].apply(lambda x: Month_Converter(x)).astype(float)\n",
    "test_data['Credit_History_Age'] = test_data['Credit_History_Age'].apply(lambda x: Month_Converter(x)).astype(float)\n",
    "\n",
    "# Handle categorical variables\n",
    "train_data['Payment_Behaviour'] = train_data['Payment_Behaviour'].replace('!@9#%8', np.nan)\n",
    "test_data['Payment_Behaviour'] = test_data['Payment_Behaviour'].replace('!@9#%8', np.nan)\n",
    "train_data['Credit_Score'] = train_data['Credit_Score'].replace({'Poor': 0, 'Standard': 1, 'Good': 2})\n",
    "\n",
    "# Impute missing values in categorical columns based on mode within groups\n",
    "columns_to_impute_mode = ['Profession', 'Payment_Behaviour']\n",
    "def fill_missing_with_group_mode(df, groupby, column):\n",
    "    mode_per_group = df.groupby(groupby)[column].transform(lambda x: x.mode()[0] if not x.mode().empty else np.nan)\n",
    "    df[column].fillna(mode_per_group, inplace=True)\n",
    "\n",
    "for col in columns_to_impute_mode:\n",
    "    fill_missing_with_group_mode(train_data, 'ID', col)\n",
    "    fill_missing_with_group_mode(test_data, 'ID', col)\n",
    "\n",
    "# Convert Loan_Type to binary columns\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "train_data['Loan_Type'] = train_data['Loan_Type'].fillna('Not Specified').str.replace(r'\\band \\b', '', regex=True).str.strip()\n",
    "train_data['Loan_Type_List'] = train_data['Loan_Type'].str.split(', ')\n",
    "mlb = MultiLabelBinarizer()\n",
    "loan_type_encoded_train = mlb.fit_transform(train_data['Loan_Type_List'])\n",
    "loan_type_df_train = pd.DataFrame(loan_type_encoded_train, columns=mlb.classes_, index=train_data.index)\n",
    "train_data = pd.concat([train_data, loan_type_df_train], axis=1).drop(columns=['Loan_Type', 'Loan_Type_List'])\n",
    "\n",
    "# Apply similar transformation to test data\n",
    "test_data['Loan_Type'] = test_data['Loan_Type'].fillna('Not Specified').str.replace(r'\\band \\b', '', regex=True).str.strip()\n",
    "test_data['Loan_Type_List'] = test_data['Loan_Type'].str.split(', ')\n",
    "loan_type_encoded_test = mlb.transform(test_data['Loan_Type_List'])\n",
    "loan_type_df_test = pd.DataFrame(loan_type_encoded_test, columns=mlb.classes_, index=test_data.index)\n",
    "test_data = pd.concat([test_data, loan_type_df_test], axis=1).drop(columns=['Loan_Type', 'Loan_Type_List'])\n",
    "\n",
    "# Encode other categorical features\n",
    "categorical_columns = ['Month', 'Profession', 'Credit_Mix', 'Payment_of_Min_Amount', 'Payment_Behaviour']\n",
    "label_encoders = {}\n",
    "for column in categorical_columns:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    train_data[column] = label_encoders[column].fit_transform(train_data[column])\n",
    "    test_data[column] = label_encoders[column].transform(test_data[column])\n",
    "\n",
    "# Impute missing values in numeric columns\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "columns_to_impute = train_data.loc[:, 'Age':'Monthly_Balance'].columns\n",
    "train_data[columns_to_impute] = imputer.fit_transform(train_data[columns_to_impute])\n",
    "test_data[columns_to_impute] = imputer.transform(test_data[columns_to_impute])\n",
    "\n",
    "# Define features and target\n",
    "X = train_data.loc[:, 'Month':'Monthly_Balance']\n",
    "y = train_data['Credit_Score']\n",
    "\n",
    "# Apply RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)\n",
    "\n",
    "# Scale test data\n",
    "X_test = test_data.loc[:, 'Month':'Monthly_Balance']\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "# Define models and parameters\n",
    "smote = SMOTE()\n",
    "X_sm, y_sm = smote.fit_resample(X_scaled, y)\n",
    "skfold = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "# Decision Tree\n",
    "tree_params = {\"criterion\": [\"entropy\"], \"splitter\": [\"best\"], \"max_depth\": [15], \"min_samples_split\": [2], \"min_samples_leaf\": [5]}\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_cv = GridSearchCV(tree_clf, tree_params, scoring=\"accuracy\", n_jobs=-1, verbose=1, cv=skfold)\n",
    "tree_cv.fit(X_sm, y_sm)\n",
    "\n",
    "# Random Forest\n",
    "rf_params = {'n_estimators': [200], 'max_features': ['sqrt'], 'max_depth': [10], 'min_samples_split': [2], 'min_samples_leaf': [4], 'bootstrap': [True]}\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "rf_cv = GridSearchCV(rf_clf, rf_params, scoring=\"accuracy\", cv=3, verbose=2, n_jobs=-1)\n",
    "rf_cv.fit(X_sm, y_sm)\n",
    "\n",
    "# XGBoost\n",
    "xgb_params = {'n_estimators': [200], 'max_depth': [15, 10], 'learning_rate': [0.5, 0.25], 'gamma': [0.03]}\n",
    "xgb_clf = XGBClassifier(random_state=42)\n",
    "xgb_cv = GridSearchCV(xgb_clf, xgb_params, scoring='accuracy', cv=3, verbose=2, n_jobs=-1)\n",
    "xgb_cv.fit(X_sm, y_sm)\n",
    "\n",
    "# KNN\n",
    "knn_params = {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance'], 'metric': ['euclidean', 'manhattan']}\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_cv = GridSearchCV(knn_clf, knn_params, scoring='accuracy', cv=3, verbose=2, n_jobs=-1)\n",
    "knn_cv.fit(X_scaled, y)\n",
    "\n",
    "# Naive Bayes\n",
    "nb_clf = GaussianNB()\n",
    "nb_scores = cross_val_score(nb_clf, X_scaled, y, cv=skfold, scoring='accuracy')\n",
    "nb_accuracy = nb_scores.mean()\n",
    "\n",
    "# Compare model performances\n",
    "models = {\n",
    "    'Decision Tree': tree_cv.best_score_,\n",
    "    'Random Forest': rf_cv.best_score_,\n",
    "    'XGBoost': xgb_cv.best_score_,\n",
    "    'KNN': knn_cv.best_score_,\n",
    "    'Naive Bayes': nb_accuracy\n",
    "}\n",
    "\n",
    "best_model_name = max(models, key=models.get)\n",
    "print(f\"\\nBest performing model: {best_model_name} with accuracy: {models[best_model_name]:.4f}\")\n",
    "\n",
    "# Get the best model\n",
    "if best_model_name == 'Decision Tree':\n",
    "    best_model = tree_cv.best_estimator_\n",
    "elif best_model_name == 'Random Forest':\n",
    "    best_model = rf_cv.best_estimator_\n",
    "elif best_model_name == 'XGBoost':\n",
    "    best_model = xgb_cv.best_estimator_\n",
    "elif best_model_name == 'KNN':\n",
    "    best_model = knn_cv.best_estimator_\n",
    "else:\n",
    "    best_model = nb_clf\n",
    "\n",
    "# Make predictions on test set\n",
    "predictions = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Convert numeric predictions back to categories\n",
    "prediction_map = {0: 'Poor', 1: 'Standard', 2: 'Good'}\n",
    "predictions_categorical = [prediction_map[pred] for pred in predictions]\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_data['ID'],\n",
    "    'Credit_Score': predictions_categorical\n",
    "})\n",
    "\n",
    "# Save predictions to CSV\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"\\nPredictions have been saved to 'credit_score_predictions.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
